
무중단 배포는 서비스 중단 없이 새로운 버전의 애플리케이션을 배포하는 기술입니다. 사용자 경험을 향상시키고 비즈니스 연속성을 보장하는 중요한 DevOps 실천 방법입니다.
### 무중단 배포의 핵심 원칙
- **서비스 가용성 유지**: 배포 중에도 서비스가 정상적으로 동작
- **점진적 전환**: 트래픽을 점진적으로 새 버전으로 전환
- **롤백 가능성**: 문제 발생 시 즉시 이전 버전으로 복구
- **모니터링**: 배포 과정에서 지속적인 상태 모니터링

---

## 배포 전략 비교

### 1. 롤링 업데이트 (Rolling Update)
**특징**: 기존 파드를 하나씩 새 버전으로 교체

**장점**:
- 리소스 효율적 (추가 리소스 최소화)
- 간단한 구현

**단점**:
- `readinessProbe` 설정이 중요
- 일시적인 연결 거부 가능성
- 롤백 시 전체 재배포 필요

**적용 시나리오**: 
- 단순한 애플리케이션
- 리소스 제약 환경
- 빠른 배포가 필요한 경우

### 2. 블루-그린 배포 (Blue-Green Deployment)
**특징**: 완전히 새로운 환경을 구축 후 트래픽 전환

**장점**:
- 빠른 롤백 (DNS/로드밸런서 설정만 변경)
- 완전한 환경 격리
- 테스트 환경으로 활용 가능

**단점**:
- 리소스 사용량 2배
- 데이터베이스 마이그레이션 복잡성
- 전환 시 일시적 500 에러 발생

**적용 시나리오**:
- 중요 업무 시스템
- 데이터베이스 스키마 변경이 있는 경우
- 완전한 롤백이 필요한 경우

### 3. 카나리 배포 (Canary Deployment)
**특징**: 트래픽을 점진적으로 새 버전으로 전환

**장점**:
- 위험 최소화
- 실시간 모니터링 가능
- 세밀한 트래픽 제어

**단점**:
- 복잡한 설정
- 모니터링 인프라 필요
- 장기간 배포 과정

**적용 시나리오**:
- 대규모 사용자 기반
- 안정성이 중요한 서비스
- A/B 테스트가 필요한 경우

---

## ArgoCD Rollouts 설치

### 1. 네임스페이스 생성
```bash
kubectl create namespace argo-rollouts
```

### 2. CRD 및 컨트롤러 배포
```bash
kubectl apply -n argo-rollouts \
  -f https://github.com/argoproj/argo-rollouts/releases/latest/download/install.yaml
```

### 3. kubectl 플러그인 설치
```bash
# Linux
curl -LO https://github.com/argoproj/argo-rollouts/releases/latest/download/kubectl-argo-rollouts-linux-amd64
sudo install -o root -g root -m 0755 kubectl-argo-rollouts-linux-amd64 /usr/local/bin/kubectl-argo-rollouts

# macOS
curl -LO https://github.com/argoproj/argo-rollouts/releases/latest/download/kubectl-argo-rollouts-darwin-amd64
sudo install -o root -g root -m 0755 kubectl-argo-rollouts-darwin-amd64 /usr/local/bin/kubectl-argo-rollouts

# Windows
curl -LO https://github.com/argoproj/argo-rollouts/releases/latest/download/kubectl-argo-rollouts-windows-amd64.exe
# PATH에 추가하거나 원하는 위치로 이동
```

### 4. 설치 확인
```bash
kubectl argo rollouts version
```

---

## GitOps 기반 무중단 배포

### GitOps 흐름
1. **코드 변경** → Git 저장소에 푸시
2. **CI/CD 파이프라인** → 새 이미지 빌드 및 레지스트리 푸시
3. **GitOps 도구** → Git 저장소의 매니페스트 감지
4. **자동 배포** → 클러스터에 변경사항 적용
5. **모니터링** → 배포 상태 및 애플리케이션 성능 확인

---
## 실제 구현 예시

### 1. 카나리 배포 Rollout 정의

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: app-fe
  namespace: test-dev
spec:
  replicas: 4
  selector:
    matchLabels:
      app: app-fe
  strategy:
    canary:
      maxSurge: 1
      maxUnavailable: 0
      steps:
        - setWeight: 20
        - pause: {}
        - setWeight: 40
        - pause: { duration: 20 }
        - setWeight: 60
        - pause: { duration: 20 }
        - setWeight: 80
        - pause: { duration: 20 }
  minReadySeconds: 30
  revisionHistoryLimit: 2
  template:
    metadata:
      labels:
        app: app-fe
    spec:
      imagePullSecrets:
        - name: harbor-secret
      containers:
        - name: app-fe
          image: cicd.harbor.dev.eris.go.kr/test-app/front:0.0.16
          imagePullPolicy: Always
          ports:
            - containerPort: 8080
          env:
            - name: JAEGER_AGENT_HOST
              value: "localhost"
            - name: JAEGER_AGENT_PORT
              value: "6831"
        - name: jaeger-agent
          image: jaegertracing/jaeger-agent:latest
          args:
            - "--reporter.grpc.host-port=jaeger-prod-collector.observability:14250"
            - "--reporter.type=grpc"
          ports:
            - containerPort: 5775
              protocol: UDP
            - containerPort: 6831
              protocol: UDP
            - containerPort: 6832
              protocol: UDP
            - containerPort: 5778
              protocol: TCP
```

### 2. Service 정의

```yaml
apiVersion: v1
kind: Service
metadata:
  name: frontend-service
  namespace: test-dev
spec:
  selector:
    app: app-fe
  ports:
    - name: http
      port: 8080
      targetPort: 8080
  type: ClusterIP
```

---
## Kong + Kubernetes Service 포트 정리

> **중요**: Kong Ingress가 Service `port`를 "Pod 실제 포트"라고 믿고 직접 연결하기 때문에,  
> Kong 경로를 타는 서비스는 **`Service.port` = `spec.template.containers[*].containerPort`** 를 맞추는 것이 중요

| 구분 | 동작 방식 | 결과 |
|------|-----------|------|
| **Kong 경유** (L7 프록시가 **Service 포트**로 바로 연결) | 사용자 → Kong → `Service.clusterIP:port` → **PodIP:`port`** | 포트가 다르면 **ECONNREFUSED / delayed connect error** |
| **Kong 미경유** (내부 또는 ClusterIP 직접 호출) | kube‑proxy가 `targetPort`로 NAT | `port ≠ targetPort` 여도 정상 |

### 포트 설정 모범 사례
```yaml
# Pod 정의
spec:
  containers:
    - name: app
      ports:
        - containerPort: 8080  # 실제 애플리케이션 포트

---
# Service 정의
spec:
  ports:
    - port: 8080        # Kong이 연결할 포트
      targetPort: 8080  # Pod의 실제 포트
```

---

## 배포 관리 명령어

### 1. 배포 상태 확인
```bash
# 실시간 배포 상태 모니터링
kubectl argo rollouts get rollout app-fe -n test-dev -w

# 배포 히스토리 확인
kubectl argo rollouts history app-fe -n test-dev

# 특정 리비전으로 롤백
kubectl argo rollouts undo app-fe -n test-dev --to-revision=2
```

### 2. 수동 배포 제어
```bash
# 배포 진행 (다음 단계로)
kubectl argo rollouts promote app-fe -n test-dev

# 배포 중단
kubectl argo rollouts pause app-fe -n test-dev

# 배포 재개
kubectl argo rollouts resume app-fe -n test-dev

# 배포 중단
kubectl argo rollouts abort app-fe -n test-dev
```

### 3. 로그 및 이벤트 확인
```bash
# 롤아웃 이벤트 확인
kubectl describe rollout app-fe -n test-dev

# 파드 로그 확인
kubectl logs -l app=app-fe -n test-dev -f

# 서비스 엔드포인트 확인
kubectl get endpoints frontend-service -n test-dev
```

---

## 트러블슈팅

### 1. 일반적인 문제들

#### Connection Refused 오류
**증상**: 배포 중 `ECONNREFUSED` 오류 발생

**원인**:
- `readinessProbe` 설정 부족
- 포트 불일치 (특히 Kong 사용 시)
- 새 파드가 완전히 준비되기 전에 트래픽 전환

**해결 방법**:
```yaml
readinessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3
```

#### 500 에러 (Blue-Green 배포 시)
**증상**: 트래픽 전환 시 일시적 500 에러

**원인**: Blue-Green 배포의 특성상 불가피한 현상

**해결 방법**:
- 클라이언트 측 재시도 로직 구현
- 로드밸런서 설정 최적화
- 카나리 배포로 전환 고려

### 2. 모니터링 지표

#### 배포 성공률 모니터링
```bash
# 배포 상태 확인
kubectl get rollout app-fe -n test-dev -o yaml | grep -A 10 "status:"

# 파드 상태 확인
kubectl get pods -l app=app-fe -n test-dev

# 서비스 엔드포인트 확인
kubectl get endpoints frontend-service -n test-dev
```

#### 성능 지표
- 응답 시간 (Response Time)
- 에러율 (Error Rate)
- 처리량 (Throughput)
- 리소스 사용률 (CPU, Memory)

### 3. 롤백 전략

#### 자동 롤백 조건 설정
```yaml
spec:
  strategy:
    canary:
      analysis:
        templates:
          - templateName: success-rate
        args:
          - name: service-name
            value: frontend-service
        startingStep: 2
        rules:
          - name: success-rate
            template: success-rate
            failureLimit: 3
```

#### 수동 롤백 절차
1. 배포 상태 확인
2. 문제 원인 분석
3. 롤백 명령 실행
4. 서비스 정상화 확인
