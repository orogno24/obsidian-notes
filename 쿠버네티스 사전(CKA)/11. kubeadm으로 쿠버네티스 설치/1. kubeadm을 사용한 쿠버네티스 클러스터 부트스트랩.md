## kubeadm 소개

- **kubeadm이란?** 쿠버네티스 모범 사례를 사용하여 다중 노드 클러스터를 설정하는 도구
- **주요 기능**:
    - 여러 컴포넌트(kube-apiserver, etcd, 컨트롤러 등)의 설치 자동화
    - 보안 및 인증서 구성 자동화
    - 여러 노드에 걸친 컴포넌트 간 통신 설정 간소화

## kubeadm을 사용한 클러스터 설정 단계

### 1. 시스템 준비

- 여러 시스템 또는 VM 프로비저닝
- 물리적 머신 또는 가상 머신 사용 가능
- 하나의 노드를 마스터로, 나머지를 워커 노드로 지정

### 2. 컨테이너 런타임 설치

- 모든 노드에 컨테이너 런타임 설치 필요
- 예제에서는 containerd 사용

### 3. kubeadm 도구 설치

- 모든 노드에 kubeadm 도구 설치
- 쿠버네티스 구성 요소의 올바른 설치 및 구성 지원

### 4. 마스터 서버 초기화

- 필요한 모든 컴포넌트가 마스터 서버에 설치 및 구성됨

### 5. 네트워크 사전 요구 사항 충족

- 일반 네트워크 연결만으로는 불충분
- 마스터와 워커 노드 간 Pod 네트워크 구성 필요

### 6. 워커 노드 연결

- 워커 노드를 마스터 노드에 연결

### 7. 애플리케이션 배포

- 구성된 쿠버네티스 환경에 애플리케이션 배포

## 로컬 환경에서 클러스터 구축 데모

### 사용 도구

1. **VirtualBox**
    - 하이퍼바이저로서 가상 머신 실행 담당
    - virtualbox.org에서 다운로드 가능

2. **Vagrant**
    - VM 자동화 도구
    - 특정 구성으로 여러 VM을 쉽게 프로비저닝
    - 단일 명령어로 동일한 VM 구성 생성 가능

### 필수 사전 요구사항

- VirtualBox 설치
- Vagrant 설치
- 코스 리포지토리 클론 (Vagrant 파일 포함)

### Vagrant 파일 구성

- 1개의 마스터 노드와 2개의 워커 노드 구성
- IP 주소는 192.168.56 네트워크 사용
- VM 구성에 필요한 모든 설정 포함

### VM 프로비저닝 과정

1. `vagrant status` 명령으로 VM 상태 확인
2. `vagrant up` 명령으로 모든 VM 프로비저닝
    - Ubuntu Bionic 64 베이스 이미지 사용
    - 마스터 노드와 워커 노드 순차적 프로비저닝
3. VM 프로비저닝 완료 후 다시 `vagrant status`로 확인
    - 모든 노드가 running 상태인지 확인

### VM 접속 방법

- `vagrant ssh <노드_이름>` 명령으로 특정 노드에 접속
    - 예: `vagrant ssh kubemaster`
    - 예: `vagrant ssh kubenode01`
    - 예: `vagrant ssh kubenode02`
- `logout` 명령으로 세션 종료

## 추가 참고사항

- kubeadm은 쿠버네티스 클러스터 설정의 복잡성을 크게 줄여줌
- 수동으로 모든 컴포넌트를 설치하고 구성하는 것보다 훨씬 효율적
- 로컬 환경에서의 실습을 통해 실제 프로덕션 환경 구성 방법 이해 가능
- VirtualBox와 Vagrant의 조합으로 쉽게 테스트 환경 구축 가능
- 모든 노드에서 동일한 구성을 사용하여 일관된 환경 유지

# 쿠버네티스 클러스터 부트스트랩

## 환경 설정

- **노드 구성**: 1개 마스터 노드 + 2개 워커 노드
- **IP 주소 구성**:
    - 마스터 노드: 192.168.56.11
    - 워커 노드 1: 192.168.56.21
    - 워커 노드 2: 192.168.56.22
- **네트워크 인터페이스**: enp0s8을 클러스터 통신에 사용

## 설치 준비 문서

- **주요 문서**:
    1. "Installing kubeadm" 페이지
    2. "Creating a cluster with kubeadm" 페이지
    3. 다중 마스터 구성 시 "Creating highly available clusters with kubeadm" 참조

## 설치 과정

### 1. kubeadm 설치

모든 노드에서 다음 명령 실행:

```bash
# Kubernetes 공개 서명 키 다운로드
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# Kubernetes 저장소 추가
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

# 패키지 업데이트 및 kubeadm 설치
sudo apt update
sudo apt install -y kubelet kubeadm kubectl
```

### 2. 컨테이너 런타임 설치

모든 노드에서 containerd 설치:

```bash
sudo apt update
sudo apt install -y containerd
```

### 3. cgroup 드라이버 구성

- **중요**: kubelet과 컨테이너 런타임의 cgroup 드라이버가 일치해야 함
- systemd 확인: `ps -p 1` (출력이 systemd면 systemd 드라이버 사용)

**containerd 구성**:

1. 구성 디렉토리 생성:
    
    ```bash
    sudo mkdir -p /etc/containerd
    ```
    
2. 기본 구성 생성 및 수정:
    
    ```bash
    sudo containerd config default | sudo sed -e 's/SystemdCgroup = false/SystemdCgroup = true/' > /etc/containerd/config.toml
    ```
    
3. containerd 재시작:
    
    ```bash
    sudo systemctl restart containerd
    ```
    

### 4. 마스터 노드 초기화

마스터 노드에서만 실행:

```bash
sudo kubeadm init \
  --apiserver-advertise-address=192.168.56.11 \
  --pod-network-cidr=10.244.0.0/16 \
  --upload-certs
```

**초기화 출력 분석**:

- CA 인증서 생성
- API 서버, etcd 인증서 생성
- 각 컴포넌트 구성 파일 생성
- 정적 파드 매니페스트 생성 및 컴포넌트 시작
- kubeconfig 파일 생성

### 5. kubeconfig 설정 (마스터 노드)

```bash
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

### 6. 네트워크 플러그인 설치

마스터 노드에서 Flannel 네트워크 플러그인 설치:

```bash
kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml
```

**참고**: Pod CIDR이 기본값(10.244.0.0/16)과 다른 경우 매니페스트 수정 필요:

1. 매니페스트 다운로드:
    
    ```bash
    wget https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml
    ```
    
2. `net-conf.json` 섹션에서 Network 값을 Pod CIDR과 일치하도록 수정

### 7. 워커 노드 연결

초기화 출력에서 제공된 join 명령을 각 워커 노드에서 실행:

```bash
sudo kubeadm join 192.168.56.11:6443 --token <token> \
  --discovery-token-ca-cert-hash sha256:<hash>
```

### 8. 클러스터 상태 확인

마스터 노드에서 확인:

```bash
kubectl get nodes
```

- 모든 노드가 Ready 상태인지 확인
- Flannel 파드 확인: `kubectl get pods -n kube-flannel`

### 9. 테스트 파드 배포

```bash
kubectl run web --image=nginx
kubectl get pod
```

## 고급 구성 옵션

### 1. 다중 마스터 구성 준비

단일 마스터에서 HA로 업그레이드 계획 시:

```bash
--control-plane-endpoint=<가상IP/로드밸런서주소>
```

- 로드밸런서를 가리키도록 설정하여 향후 확장 준비

### 2. 맞춤형 네트워크 구성

- Pod CIDR 네트워크 지정: `--pod-network-cidr=<CIDR>`
- 기본값은 사용하는 CNI에 따라 다름 (Flannel: 10.244.0.0/16)

### 3. 사용자 정의 컨테이너 런타임 소켓

기본 경로가 아닌 경우:

```bash
--cri-socket=<런타임_소켓_경로>
```

## 참고사항

- kubeadm은 Kubernetes 컴포넌트를 컨테이너로 실행하므로 마스터 노드에도 컨테이너 런타임 필요
- 모든 노드는 동일한 버전의 kubeadm, kubelet, kubectl을 실행해야 함
- 마스터 노드는 최소 2 코어 CPU와 2GB RAM 필요
- 워커 노드는 사용 케이스에 따라 리소스 요구사항 결정
- Flannel은 간단한 네트워크 플러그인이지만, Calico, Cilium 등 다른 CNI도 선택 가능
- 프로덕션 환경에서는 다중 마스터 구성 권장