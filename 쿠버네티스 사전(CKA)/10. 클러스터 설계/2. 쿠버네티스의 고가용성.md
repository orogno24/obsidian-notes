## 마스터 노드 장애 시나리오

마스터 노드가 다운되면 어떤 일이 발생할까요?

- 워커 노드와 컨테이너가 살아있는 한 애플리케이션은 계속 실행됨
- 사용자는 애플리케이션에 계속 접근 가능
- 그러나 장애 발생 시 문제점:
    - 컨테이너나 파드가 충돌하면 복구 불가
    - 레플리카셋(Replica Set)의 파드가 충돌해도 마스터의 복제 컨트롤러 부재로 새 파드 생성 불가
    - 스케줄러 부재로 노드에 파드 할당 불가
    - kube-apiserver 사용 불가로 외부에서 클러스터 관리 불가능

## 고가용성 구성의 필요성

프로덕션 환경에서는 단일 장애점(Single Point of Failure)을 방지하기 위해 고가용성 구성 필수:

- 클러스터의 모든 구성 요소에 중복성 확보
- 마스터 노드, 워커 노드, 컨트롤 플레인 컴포넌트의 이중화
- 애플리케이션은 이미 Replica Set과 서비스를 통해 다중화 구성

## 마스터 노드 고가용성 구성

![[스크린샷_19-5-2025_133545_.jpeg]]
### API 서버

- 여러 마스터 노드에서 동시에 **액티브-액티브(active-active)** 모드로 실행 가능
- 한 번에 하나의 요청만 처리하므로 병렬 실행 가능
- 로드 밸런서를 통해 여러 API 서버로 트래픽 분산
    - 로드 밸런서 유형: Nginx, HAProxy 등
    - kubectl은 로드 밸런서 주소로 요청 전송

### 스케줄러 및 컨트롤러 매니저

- **액티브-스탠바이(active-standby)** 모드로 실행
- 복제 작업 중복 방지를 위해 병렬 실행 불가
- 리더 선출(Leader Election) 프로세스로 액티브 인스턴스 결정
    - `--leader-elect` 옵션 사용 (기본값: true)
    - 리더는 엔드포인트 객체에 대한 리스(lease) 획득
    - 기본 리스 기간: 15초 (`--leader-elect-lease-duration`)
    - 액티브 프로세스는 10초마다 리스 갱신 (`--leader-elect-renew-deadline`)
    - 프로세스는 2초마다 리더가 되려고 시도 (`--leader-elect-retry-period`)

### etcd 구성

etcd 클러스터 구성에는 두 가지 토폴로지 가능:

#### 1. 스택형 컨트롤 플레인 노드 토폴로지

- etcd가 쿠버네티스 마스터 노드에 포함
- 장점: 설정과 관리 용이, 적은 수의 노드 필요
- 단점: 노드 장애 시 etcd 멤버와 컨트롤 플레인 인스턴스 모두 상실

#### 2. 외부 etcd 서버 토폴로지

- etcd를 별도 서버 세트에서 실행
- 장점: 컨트롤 플레인 노드 장애가 etcd 클러스터에 영향 안 줌
- 단점: 설정이 복잡하고 외부 etcd 노드를 위한 추가 서버 필요

## 고가용성 구성 요약

- 다중 마스터 노드
- API 서버 앞단의 로드 밸런서
- 컨트롤러와 스케줄러의 리더 선출 메커니즘
- 적절한 etcd 클러스터 구성

## 추가 고려사항

- API 서버는 etcd 서버와 통신하는 유일한 컴포넌트
- etcd는 분산 시스템으로, 어떤 인스턴스를 통해서도 데이터 읽기/쓰기 가능
- kube-apiserver 구성에 모든 etcd 서버 목록 지정 필요
- 다음 강의에서는 etcd 서버의 클러스터 설정과 권장 노드 수에 대한 모범 사례 논의 예정

## 최종 구성

- 고가용성을 위한 다중 마스터 노드
- API 서버용 로드 밸런서
- 클러스터 내 총 5개 노드