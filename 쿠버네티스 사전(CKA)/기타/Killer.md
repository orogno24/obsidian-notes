## ğŸ“‹ ì‹œí—˜ ì•ˆë‚´ì‚¬í•­

- ê° ë¬¸ì œëŠ” íŠ¹ì • ì¸ìŠ¤í„´ìŠ¤ì—ì„œ í•´ê²°í•´ì•¼ í•¨
- ë‹¤ë¥¸ ì¸ìŠ¤í„´ìŠ¤ë¡œ ì´ë™í•˜ë ¤ë©´ `exit` ëª…ë ¹ì–´ë¡œ ë©”ì¸ í„°ë¯¸ë„ë¡œ ëŒì•„ê°„ í›„ ssh ì—°ê²°
- í•„ìš”ì‹œ `sudo -i`ë¡œ root ê¶Œí•œ íšë“

---

## ğŸ”§ Question 1 | Contexts

**ì¸ìŠ¤í„´ìŠ¤**: `ssh cka9412`

### ğŸ“ ë¬¸ì œ

`/opt/course/1/kubeconfig` íŒŒì¼ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ì €ì¥í•˜ì„¸ìš”:

1. ëª¨ë“  kubeconfig context ì´ë¦„ì„ `/opt/course/1/contexts`ì— í•œ ì¤„ì”© ì €ì¥
2. í˜„ì¬ context ì´ë¦„ì„ `/opt/course/1/current-context`ì— ì €ì¥
3. `account-0027` ì‚¬ìš©ìì˜ client-certificateë¥¼ base64 ë””ì½”ë”©í•˜ì—¬ `/opt/course/1/cert`ì— ì €ì¥

### ğŸ’¡ í•´ë‹µ

**Step 1: Context ì´ë¦„ë“¤ ì¶”ì¶œ**

```bash
ssh cka9412

# ëª¨ë“  context í™•ì¸
k --kubeconfig /opt/course/1/kubeconfig config get-contexts

# context ì´ë¦„ë§Œ ì¶”ì¶œí•˜ì—¬ ì €ì¥
k --kubeconfig /opt/course/1/kubeconfig config get-contexts -oname > /opt/course/1/contexts
```

**Step 2: í˜„ì¬ context í™•ì¸**

```bash
k --kubeconfig /opt/course/1/kubeconfig config current-context > /opt/course/1/current-context
```

**Step 3: ì¸ì¦ì„œ ì¶”ì¶œ ë° ë””ì½”ë”©**

```bash
# ë°©ë²• 1: ìˆ˜ë™ìœ¼ë¡œ í™•ì¸ í›„ ë””ì½”ë”©
k --kubeconfig /opt/course/1/kubeconfig config view -o yaml --raw
echo LS0tLS1CRUdJTi... | base64 -d > /opt/course/1/cert

# ë°©ë²• 2: ìë™í™”
k --kubeconfig /opt/course/1/kubeconfig config view --raw -ojsonpath="{.users[0].user.client-certificate-data}" | base64 -d > /opt/course/1/cert
```

---

## ğŸ”§ Question 2 | MinIO Operator, CRD Config, Helm Install

**ì¸ìŠ¤í„´ìŠ¤**: `ssh cka7968`

### ğŸ“ ë¬¸ì œ

Helmì„ ì‚¬ìš©í•˜ì—¬ MinIO Operatorë¥¼ ì„¤ì¹˜í•˜ê³  Tenant CRDë¥¼ êµ¬ì„±í•˜ì„¸ìš”:

1. `minio` Namespace ìƒì„±
2. `minio/operator` Helm chartë¥¼ `minio-operator`ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ì„¤ì¹˜
3. `/opt/course/2/minio-tenant.yaml`ì—ì„œ `features` í•˜ìœ„ì— `enableSFTP: true` ì¶”ê°€
4. Tenant ë¦¬ì†ŒìŠ¤ ìƒì„±

### ğŸ’¡ í•´ë‹µ

**Step 1: Namespace ìƒì„±**

```bash
ssh cka7968
k create ns minio
```

**Step 2: Helm Chart ì„¤ì¹˜**

```bash
# ì‚¬ìš© ê°€ëŠ¥í•œ chart í™•ì¸
helm repo list
helm search repo

# MinIO operator ì„¤ì¹˜
helm -n minio install minio-operator minio/operator

# ì„¤ì¹˜ í™•ì¸
helm -n minio ls
k -n minio get pod
```

**Step 3: Tenant YAML ìˆ˜ì •**

```yaml
# /opt/course/2/minio-tenant.yaml
apiVersion: minio.min.io/v2
kind: Tenant
metadata:
  name: tenant
  namespace: minio
  labels:
    app: minio
spec:
  features:
    bucketDNS: false
    enableSFTP: true                     # ì´ ì¤„ ì¶”ê°€
  image: quay.io/minio/minio:latest
  # ... ë‚˜ë¨¸ì§€ ì„¤ì •
```

**Step 4: Tenant ë¦¬ì†ŒìŠ¤ ìƒì„±**

```bash
k -f /opt/course/2/minio-tenant.yaml apply
k -n minio get tenant
```

### ğŸ“š ê°œë… ì •ë¦¬

- **Helm Chart**: Kubernetes YAML í…œí”Œë¦¿ íŒŒì¼ë“¤ì˜ íŒ¨í‚¤ì§€
- **Helm Release**: Chartê°€ ì„¤ì¹˜ëœ ì¸ìŠ¤í„´ìŠ¤
- **Operator**: Kubernetes APIì™€ í†µì‹ í•˜ë©° CRDì™€ í•¨ê»˜ ë™ì‘í•˜ëŠ” Pod
- **CRD**: Kubernetes APIì˜ ì»¤ìŠ¤í…€ í™•ì¥

---

## ğŸ”§ Question 3 | Scale down StatefulSet

**ì¸ìŠ¤í„´ìŠ¤**: `ssh cka3962`

### ğŸ“ ë¬¸ì œ

`project-h800` Namespaceì— ìˆëŠ” `o3db-*` Podë“¤ì„ 1ê°œ replicaë¡œ ìŠ¤ì¼€ì¼ ë‹¤ìš´í•˜ì„¸ìš”.

### ğŸ’¡ í•´ë‹µ

```bash
ssh cka3962

# Pod í™•ì¸
k -n project-h800 get pod | grep o3db

# StatefulSet í™•ì¸
k -n project-h800 get deploy,ds,sts | grep o3db

# ìŠ¤ì¼€ì¼ ë‹¤ìš´
k -n project-h800 scale sts o3db --replicas 1

# ê²°ê³¼ í™•ì¸
k -n project-h800 get sts o3db
```

---

## ğŸ”§ Question 4 | Find Pods first to be terminated

**ì¸ìŠ¤í„´ìŠ¤**: `ssh cka2556`

### ğŸ“ ë¬¸ì œ

`project-c13` Namespaceì—ì„œ ë¦¬ì†ŒìŠ¤ ë¶€ì¡± ì‹œ ê°€ì¥ ë¨¼ì € ì¢…ë£Œë  Podë“¤ì„ ì°¾ì•„ `/opt/course/4/pods-terminated-first.txt`ì— ì €ì¥í•˜ì„¸ìš”.

### ğŸ’¡ í•´ë‹µ

**ê°œë…**: ë¦¬ì†ŒìŠ¤ ìš”ì²­ì´ ì—†ëŠ” Podë“¤ì´ ë¨¼ì € ì¢…ë£Œë¨ (QoS Class: BestEffort)

```bash
ssh cka2556

kubectl get pod -n project-c13 -o custom-columns=NAME:.metadata.name,QOS:.status.qosClass

# ë°©ë²• 1: ìˆ˜ë™ í™•ì¸
k -n project-c13 describe pod | grep -A 3 -E 'Requests|^Name:'

# ë°©ë²• 2: ìë™í™”
k -n project-c13 get pod -o jsonpath="{range .items[*]} {.metadata.name}{.spec.containers[*].resources}{'\n'}"

# ë°©ë²• 3: QoS Class í™•ì¸
k get pods -n project-c13 -o jsonpath="{range .items[*]}{.metadata.name} {.status.qosClass}{'\n'}"
```

**ê²°ê³¼ íŒŒì¼**:

```text
# /opt/course/4/pods-terminated-first.txt
c13-3cc-runner-heavy-65588d7d6-djtv9map
c13-3cc-runner-heavy-65588d7d6-v8kf5map
c13-3cc-runner-heavy-65588d7d6-wwpb4map
```

### ğŸ“š QoS Classes

- **Guaranteed**: requests = limits
- **Burstable**: requests < limits
- **BestEffort**: requests/limits ì—†ìŒ (ë¨¼ì € ì¢…ë£Œë¨)

---

## ğŸ”§ Question 5 | Kustomize configure HPA Autoscaler

**ì¸ìŠ¤í„´ìŠ¤**: `ssh cka5774`

### ğŸ“ ë¬¸ì œ

Kustomizeë¥¼ ì‚¬ìš©í•˜ì—¬ HPA(HorizontalPodAutoscaler)ë¥¼ êµ¬ì„±í•˜ì„¸ìš”:

1. `horizontal-scaling-config` ConfigMap ì™„ì „ ì œê±°
2. `api-gateway` Deploymentìš© HPA ì¶”ê°€ (min: 2, max: 4, CPU: 50%)
3. prod í™˜ê²½ì—ì„œëŠ” max 6 replicas
4. stagingê³¼ prodì— ë³€ê²½ì‚¬í•­ ì ìš©

### ğŸ’¡ í•´ë‹µ

**Step 1: ConfigMap ì œê±°**

```bash
ssh cka5774
cd /opt/course/5/api-gateway

# base, staging, prodì˜ api-gateway.yamlì—ì„œ ConfigMap ì„¹ì…˜ ì œê±°
vim base/api-gateway.yaml
vim staging/api-gateway.yaml  
vim prod/api-gateway.yaml
```

**Step 2: Baseì— HPA ì¶”ê°€**

```yaml
# base/api-gateway.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-gateway
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-gateway
  minReplicas: 2
  maxReplicas: 4
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 50
---
# ... ê¸°ì¡´ ServiceAccountì™€ Deployment
```

**Step 3: Prodì—ì„œ maxReplicas ì˜¤ë²„ë¼ì´ë“œ**

```yaml
# prod/api-gateway.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-gateway
spec:
  maxReplicas: 6
---
# ... ê¸°ì¡´ Deployment
```

**Step 4: ë³€ê²½ì‚¬í•­ ì ìš©**

```bash
# Staging ì ìš©
k kustomize staging | kubectl diff -f -
k kustomize staging | kubectl apply -f -

# Prod ì ìš©  
k kustomize prod | kubectl apply -f -

# ê¸°ì¡´ ConfigMap ìˆ˜ë™ ì‚­ì œ
k -n api-gateway-staging delete cm horizontal-scaling-config
k -n api-gateway-prod delete cm horizontal-scaling-config
```

---

## ğŸ”§ Question 6 | Storage, PV, PVC, Pod volume

**ì¸ìŠ¤í„´ìŠ¤**: `ssh cka7968`

### ğŸ“ ë¬¸ì œ

ìŠ¤í† ë¦¬ì§€ ë¦¬ì†ŒìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”:

1. PV `safari-pv`: 2Gi, ReadWriteOnce, hostPath `/Volumes/Data`
2. PVC `safari-pvc`: `project-t230` namespaceì— 2Gi ìš”ì²­
3. Deployment `safari`: PVCë¥¼ `/tmp/safari-data`ì— ë§ˆìš´íŠ¸

### ğŸ’¡ í•´ë‹µ

**Step 1: PersistentVolume ìƒì„±**

```yaml
# 6_pv.yaml
kind: PersistentVolume
apiVersion: v1
metadata:
 name: safari-pv
spec:
 capacity:
  storage: 2Gi
 accessModes:
  - ReadWriteOnce
 hostPath:
  path: "/Volumes/Data"
```

**Step 2: PersistentVolumeClaim ìƒì„±**

```yaml
# 6_pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: safari-pvc
  namespace: project-t230
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
     storage: 2Gi
```

**Step 3: Deployment ìƒì„±**

```yaml
# 6_dep.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: safari
  name: safari
  namespace: project-t230
spec:
  replicas: 1
  selector:
    matchLabels:
      app: safari
  template:
    metadata:
      labels:
        app: safari
    spec:
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: safari-pvc
      containers:
      - image: httpd:2-alpine
        name: container
        volumeMounts:
        - name: data
          mountPath: /tmp/safari-data
```

**ì ìš© ë° í™•ì¸**:

```bash
k -f 6_pv.yaml create
k -f 6_pvc.yaml create
k -f 6_dep.yaml create

# Bound ìƒíƒœ í™•ì¸
k -n project-t230 get pv,pvc
```

---

## ğŸ”§ Question 7 | Node and Pod Resource Usage

**ì¸ìŠ¤í„´ìŠ¤**: `ssh cka5774`

### ğŸ“ ë¬¸ì œ

kubectlì„ ì‚¬ìš©í•˜ëŠ” bash ìŠ¤í¬ë¦½íŠ¸ 2ê°œë¥¼ ì‘ì„±í•˜ì„¸ìš”:

1. `/opt/course/7/node.sh`: Node ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í‘œì‹œ
2. `/opt/course/7/pod.sh`: Podì™€ ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í‘œì‹œ

### ğŸ’¡ í•´ë‹µ

```bash
# /opt/course/7/node.sh
kubectl top node

# /opt/course/7/pod.sh  
kubectl top pod --containers=true
```

---

## ğŸ”§ Question 8 | Update Kubernetes Version and join cluster

**ì¸ìŠ¤í„´ìŠ¤**: `ssh cka3962`

### ğŸ“ ë¬¸ì œ

`cka3962-node1` ë…¸ë“œë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  í´ëŸ¬ìŠ¤í„°ì— ì¡°ì¸í•˜ì„¸ìš”:

1. controlplaneê³¼ ë™ì¼í•œ Kubernetes ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸
2. kubeadmì„ ì‚¬ìš©í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ì— ë…¸ë“œ ì¶”ê°€

### ğŸ’¡ í•´ë‹µ

**Step 1: ë²„ì „ í™•ì¸**

```bash
ssh cka3962
k get node  # controlplane ë²„ì „ í™•ì¸ (v1.32.1)

ssh cka3962-node1
sudo -i
kubelet --version  # í˜„ì¬ ë²„ì „ í™•ì¸
```

**Step 2: kubeletê³¼ kubectl ì—…ë°ì´íŠ¸**

```bash
# worker ë…¸ë“œì—ì„œ
apt update
apt install kubectl=1.32.1-1.1 kubelet=1.32.1-1.1
service kubelet restart
```

**Step 3: ì¡°ì¸ í† í° ìƒì„±**

```bash
# controlplaneì—ì„œ
sudo -i
kubeadm token create --print-join-command
```

**Step 4: í´ëŸ¬ìŠ¤í„° ì¡°ì¸**

```bash
# worker ë…¸ë“œì—ì„œ ìœ„ì—ì„œ ì¶œë ¥ëœ ëª…ë ¹ì–´ ì‹¤í–‰
kubeadm join 192.168.100.31:6443 --token xxx --discovery-token-ca-cert-hash sha256:xxx

# ê²°ê³¼ í™•ì¸
k get node
```

---

## ğŸ”§ Question 9 | Contact K8s Api from inside Pod

**ì¸ìŠ¤í„´ìŠ¤**: `ssh cka9412`

### ğŸ“ ë¬¸ì œ

`project-swan` Namespaceì˜ `secret-reader` ServiceAccountì„ ì‚¬ìš©í•˜ëŠ” Podë¥¼ ìƒì„±í•˜ê³ , Pod ë‚´ë¶€ì—ì„œ curlë¡œ Kubernetes APIë¥¼ ì¿¼ë¦¬í•˜ì—¬ ëª¨ë“  Secretì„ ì¡°íšŒí•˜ì„¸ìš”.

### ğŸ’¡ í•´ë‹µ

**Step 1: Pod ìƒì„±**

```yaml
# 9.yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    run: api-contact
  name: api-contact
  namespace: project-swan
spec:
  serviceAccountName: secret-reader
  containers:
  - image: nginx:1-alpine
    name: api-contact
  dnsPolicy: ClusterFirst
  restartPolicy: Always
```

**Step 2: API í˜¸ì¶œ**

```bash
k -n project-swan exec api-contact -it -- sh

# ServiceAccount í† í° ì‚¬ìš©
TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)
curl -k https://kubernetes.default/api/v1/secrets -H "Authorization: Bearer ${TOKEN}"

# ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
curl -k https://kubernetes.default/api/v1/secrets -H "Authorization: Bearer ${TOKEN}" > result.json
exit

# ê²°ê³¼ ë³µì‚¬
k -n project-swan exec api-contact -it -- cat result.json > /opt/course/9/result.json
```

**ë³´ì•ˆ ê°œì„  (CA ì¸ì¦ì„œ ì‚¬ìš©)**:

```bash
CACERT=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
curl --cacert ${CACERT} https://kubernetes.default/api/v1/secrets -H "Authorization: Bearer ${TOKEN}"
```

---

## ğŸ”§ Question 10 | RBAC ServiceAccount Role RoleBinding

**ì¸ìŠ¤í„´ìŠ¤**: `ssh cka3962`

### ğŸ“ ë¬¸ì œ

`project-hamster` Namespaceì— RBAC ì„¤ì •ì„ ìƒì„±í•˜ì„¸ìš”:

1. ServiceAccount `processor` ìƒì„±
2. Role `processor`: Secretê³¼ ConfigMap ìƒì„± ê¶Œí•œë§Œ í—ˆìš©
3. RoleBinding `processor`: SAì™€ Role ì—°ê²°

### ğŸ’¡ í•´ë‹µ

**Step 1: ServiceAccount ìƒì„±**

```bash
ssh cka3962
k -n project-hamster create sa processor
```

**Step 2: Role ìƒì„±**

```bash
k -n project-hamster create role processor --verb=create --resource=secret --resource=configmap
```

**Step 3: RoleBinding ìƒì„±**

```bash
k -n project-hamster create rolebinding processor --role processor --serviceaccount project-hamster:processor
```

**Step 4: ê¶Œí•œ í…ŒìŠ¤íŠ¸**

```bash
# í—ˆìš©ë˜ëŠ” ì‘ì—…
k -n project-hamster auth can-i create secret --as system:serviceaccount:project-hamster:processor  # yes
k -n project-hamster auth can-i create configmap --as system:serviceaccount:project-hamster:processor  # yes

# í—ˆìš©ë˜ì§€ ì•ŠëŠ” ì‘ì—…
k -n project-hamster auth can-i create pod --as system:serviceaccount:project-hamster:processor  # no
k -n project-hamster auth can-i delete secret --as system:serviceaccount:project-hamster:processor  # no
```

### ğŸ“š RBAC ì¡°í•©

- **Role + RoleBinding**: ë‹¨ì¼ Namespaceì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•˜ê³  ì ìš©
- **ClusterRole + ClusterRoleBinding**: í´ëŸ¬ìŠ¤í„° ì „ì²´ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•˜ê³  ì ìš©
- **ClusterRole + RoleBinding**: í´ëŸ¬ìŠ¤í„° ì „ì²´ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ë§Œ ë‹¨ì¼ Namespaceì— ì ìš©
- **Role + ClusterRoleBinding**: ë¶ˆê°€ëŠ¥

---
