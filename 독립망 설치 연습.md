
아래 단계들은 “망 개통 전까지 독립망 설치 연습”이라는 시나리오를 가정하고,  
**① 실-서비스 클러스터(online) → ② 가상 클러스터(VirtualBox, offline)** 로 Nexus Repository와 컨테이너 이미지를 옮긴 뒤, PC 인터넷선을 뽑은 상태에서도 쿠버네티스·오픈소스를 설치-배포할 수 있게 만드는 전체 흐름입니다.

---

## 1 단계 ― 온라인 Nexus에 필요한 이미지 푸시

1. **필요 이미지 목록 산출**
    
    ```bash
    # 모든 네임스페이스의 이미지 목록 → 중복 제거
    kubectl get pods -A \
      -o jsonpath='{..image}' | \
      tr -s '[[:space:]]' '\n' | sort -u > images.txt
    ```
    
    _추가로 Helm 차트, apt/yum 패키지, 파이썬 wheel 등 오프라인에서 쓸 아티팩트를 전부 정리해 둡니다._
    
2. **이미지 사전 풀(Pull) → Nexus로 태깅(Tag) → 푸시(Push)**
    
    ```bash
    REG=repository.dev.eris.go.kr:443/docker
    
    while read IMG; do
      docker pull "$IMG"
      NEW=${IMG#*/}                     # ex) nginx:1.25
      docker tag "$IMG" "$REG/$NEW"
      docker push "$REG/$NEW"
    done < images.txt
    ```
    
3. **Nexus 리포지토리 구조 예시**
    
    |타입|호스트 예시|설명|
    |---|---|---|
    |docker-proxy|docker.io 미러|공식 이미지 캐시용|
    |docker-hosted|docker private|사내 전용 이미지|
    |helm-hosted|helm-chart|`.tgz` 차트 저장|
    |raw-hosted|apt, yum, 기타|`.deb`, `.rpm`, 압축 파일 등|
    

---

## 2 단계 ― Nexus PV 백업 (Export)

> **원리**  
> Nexus 3는 ‘blob store’(바이너리) + ‘OrientDB/H2 DB’(메타데이터)를 같이 백업해야 함 ([help.sonatype.com](https://help.sonatype.com/en/prepare-a-backup.html?utm_source=chatgpt.com "Prepare a Backup - Sonatype Help"))

### 2-1. Nexus 일시 중단

```bash
kubectl scale deploy nexus-nexus-repository-manager -n cicd --replicas=0
```

### 2-2. PV 경로 확인

```bash
kubectl get pvc -n cicd | grep nexus
kubectl describe pvc <PVC_NAME> -n cicd  # PV·StorageClass·노드 경로 확인
```

### 2-3. PV 내용을 tar 로 묶기 (K8s Job)

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: nexus-backup
  namespace: cicd
spec:
  template:
    spec:
      containers:
      - name: backup
        image: alpine:3
        command: ["sh","-c","tar czf /backup/nexus-data.tgz -C /nexus-data ."]
        volumeMounts:
        - name: nexus-data
          mountPath: /nexus-data         # nexus chart의 mountPath
        - name: backup
          mountPath: /backup
      restartPolicy: Never
      volumes:
      - name: nexus-data
        persistentVolumeClaim:
          claimName: <PVC_NAME>
      - name: backup
        hostPath:                        # ★ 호스트 경로로 복사하기 쉬운 곳 지정
          path: /tmp
---
```

```bash
kubectl apply -f job-backup.yaml
kubectl logs job/nexus-backup -n cicd -f      # 완료 확인
```

### 2-4. tar 파일 가져오기

```bash
scp k8s-node:/tmp/nexus-data.tgz .
```

---

## 3 단계 ― VirtualBox 클러스터에 Nexus 복원 (Import)

### 3-1. 가상 클러스터 PV 준비

- 가상 노드(예: master-vm)에 `/opt/nexus-data` 디렉터리 생성 후 tar 압축 해제
    
    ```bash
    mkdir -p /opt/nexus-data && tar xzf nexus-data.tgz -C /opt/nexus-data
    chown -R 200:200 /opt/nexus-data         # nexus UID/GID(200) 맞춤
    ```
    
- **hostPath PV** 매니페스트
    
    ```yaml
    apiVersion: v1
    kind: PersistentVolume
    metadata:
      name: pv-nexus
    spec:
      capacity:
        storage: 20Gi
      accessModes: ["ReadWriteOnce"]
      hostPath:
        path: /opt/nexus-data
      persistentVolumeReclaimPolicy: Retain
    ```
    

### 3-2. Nexus 설치 (Helm 차트)

```bash
helm repo add oteemo https://oteemo.github.io/charts
helm upgrade --install nexus oteemo/sonatype-nexus \
  --namespace cicd --create-namespace \
  -f values.yaml \
  --set persistence.enabled=true \
  --set persistence.existingClaim=pvc-nexus \
  --set ingress.enabled=true \
  --set ingress.hosts={nexus.offline.local}
```

_values.yaml_ 예시(필수 수정)

```yaml
nexus:
  nexusSecurityContext:
    runAsUser: 200
    fsGroup: 200
  env:
    - name: INSTALL4J_ADD_VM_PARAMS
      value: >
        -Xms256m -Xmx2g
  resources:
    limits:
      memory: 4Gi
```

> Helm 차트(oteemo) 2.3.1 이상은 외부 DB 백업/복원 시 blobPath, dbPath 수동지정이 가능 ([artifacthub.io](https://artifacthub.io/packages/helm/oteemo-charts/sonatype-nexus/2.3.1?utm_source=chatgpt.com "sonatype-nexus - Oteemo Charts - Artifact Hub"))

---

## 4 단계 ― 오프라인 테스트 (PC 인터넷선 제거)

1. **/etc/hosts** 수정 (개발 PC 및 노드)
    
    ```
    192.168.56.10   nexus.offline.local
    ```
    
2. **ImagePullSecret** 생성
    
    ```bash
    kubectl create secret docker-registry nexus-auth \
      --docker-server=nexus.offline.local:443 \
      --docker-username=<id> --docker-password=<pw> \
      -n <target-namespace>
    ```
    
3. **샘플 배포**
    
    ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: nginx
    spec:
      replicas: 1
      selector:
        matchLabels: {app: nginx}
      template:
        metadata: {labels: {app: nginx}}
        spec:
          imagePullSecrets:
          - name: nexus-auth
          containers:
          - name: nginx
            image: nexus.offline.local:443/docker/nginx:1.25
    ```
    
4. **Helm 차트/패키지 설치**
    
    - `helm repo add internal https://nexus.offline.local/repository/helm-hosted`
        
    - `helm install myprom prom/prometheus -f values.yaml --repo internal`
        

---

## 5 단계 ― 운영 팁 & 체크리스트

|체크|설명|
|---|---|
|🎯 Blob store 경로 확인|복원 시 `nexus-data/blobs` 경로 무결성 필수|
|🎯 라이센스/프로 기능|Nexus Pro 전용 REST export/import 태스크는 Pro 라이센스 필요 ([help.sonatype.com](https://help.sonatype.com/en/repository-import.html?utm_source=chatgpt.com "Repository Import - Sonatype Help"))|
|🎯 Cron 백업|가상 클러스터에도 주기적 tar 백업(예: Velero RESTIC)을 걸어 둘 것|
|🎯 리포지토리 캐시|docker-proxy·maven-proxy 등은 offline 모드에서 `offline=true` 설정|
|🎯 DNS 캐시|인터넷 분리 후에도 내부 FQDN 해결되도록 CoreDNS ConfigMap에 stubDomain 추가|

---

### 한 줄 정리

> **“온라인 Nexus에서 이미지/데이터를 tar로 백업 → VirtualBox 클러스터에 hostPath PV로 복원 → 내부 DNS/Secret 설정 후 인터넷선 제거”**  
> 이 순서대로면 완전히 차단된 망에서도 쿠버네티스 배포와 오픈소스 설치가 문제없이 동작합니다. 필요-스크립트와 values.yaml만 맞춤-수정해 보세요!

| 단계                  | 핵심 한마디                                            | 왜 하는지                       | 손쉽게 하는 요령                                                                                                                                |
| ------------------- | ------------------------------------------------- | --------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| **1. 이미지 모으기**      | **“필요한 컨테이너 전부 → 사내 Nexus로 Push”**                | 인터넷이 끊기면 Docker Hub에 접속 못 함 | ```bash# ① 클러스터에서 쓰는 이미지 목록 뽑기k get pods -A -o jsonpath='{..image}'                                                                      |
| **2. Nexus 데이터 백업** | **“/nexus-data 폴더를 tar.gz로 압축”**                  | 이미지를 담은 저장소(블롭)과 DB를 통째로 빼냄 | 쿠버네티스 Job 하나로: `tar czf /backup/nexus.tgz -C /nexus-data .`                                                                              |
| **3. 가상 클러스터에 복원**  | **“VirtualBox ☞ /opt/nexus-data 에 압축 풀고 다시 띄우기”** | 오프라인에서도 똑같은 Nexus가 필요       | `bash<br>mkdir -p /opt/nexus-data<br>tar xzf nexus.tgz -C /opt/nexus-data<br>helm install nexus ... --set persistence.existingClaim=...` |
| **4. 인터넷선 뽑고 테스트**  | **“/etc/hosts + ImagePullSecret 설정 후 배포가 도나?”**   | 완전 차단 상태에서도 배포/업데이트 검증      | * hosts 파일에 `nexus.offline.local` 추가* 배포 YAML 에 `image: nexus.offline.local:443/docker/nginx:1.25`                                       |

---

#### 10초 요약

1️⃣ **이미지/패키지 다 모아서** 사내 Nexus에 넣고 →  
2️⃣ **Nexus 폴더를 tar 로 백업** →  
3️⃣ **VirtualBox 클러스터에 그대로 풀어** Nexus 재가동 →  
4️⃣ **인터넷 끊고** 이미지가 잘 Pull·배포되면 성공!

이 네 가지만 기억하면 실무 망 분리 환경도 금방 구축할 수 있어요. 🚀